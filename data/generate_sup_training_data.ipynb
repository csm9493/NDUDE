{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def make_binary_image(im):\n",
    "    im_bin=im.copy()\n",
    "    for i in range(im.shape[0]):\n",
    "        for j in range(im.shape[1]):\n",
    "            if im[i,j]>127: \n",
    "                im_bin[i,j]=1\n",
    "            else:\n",
    "                im_bin[i,j]=0\n",
    "    \n",
    "    return im_bin\n",
    "                \n",
    "def add_noise(img, delta):\n",
    "    \n",
    "    flatten_img = img.reshape((img.shape[0]*img.shape[1],)).copy()\n",
    "    img_len = flatten_img.shape[0]\n",
    "    \n",
    "    for idx in range(img_len):\n",
    "        rand_value = random.random()\n",
    "        if flatten_img[idx] == 0:\n",
    "            if rand_value < delta:\n",
    "                flatten_img[idx] = 1\n",
    "        else:\n",
    "            if rand_value < delta:\n",
    "                flatten_img[idx] = 0\n",
    "                \n",
    "    noisy_img = flatten_img.reshape(img.shape[0],img.shape[1])\n",
    "                \n",
    "    return noisy_img\n",
    "            \n",
    "\n",
    "path_dir_BSD = './source_data/training_data/'\n",
    "file_list_BSD = os.listdir(path_dir_BSD)\n",
    "file_list_BSD.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tr_dataset = 50\n",
    "binary_bsd_dataset = np.zeros(((len_tr_dataset,321,481)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len_tr_dataset):\n",
    "    \n",
    "    img = mpimg.imread(path_dir_BSD + file_list_BSD[idx])\n",
    "    gray_img = rgb2gray(img)\n",
    "    \n",
    "    if gray_img.shape[0] == 481:\n",
    "        gray_img = np.rot90(gray_img)\n",
    "        \n",
    "    binary_img = make_binary_image(gray_img)\n",
    "    \n",
    "    binary_bsd_dataset[idx,:,:] = binary_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot true img\n",
    "plt.imshow(binary_bsd_dataset[0], cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot noisy img\n",
    "plt.imshow(add_noise(binary_bsd_dataset[0], 0.2), cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "def get_onehot_context(context, nb_classes):\n",
    "    onehot_context = np_utils.to_categorical(context,nb_classes)\n",
    "    flatten_onehot_context = onehot_context.reshape(onehot_context.shape[0],onehot_context.shape[1]*onehot_context.shape[2])\n",
    "    return flatten_onehot_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_arr = [3,5,7,9,11,13,15,17,19,21]\n",
    "delta_arr = [0.05, 0.1, 0.2, 0.25]\n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "\n",
    "x_size = 321\n",
    "y_size = 481\n",
    "\n",
    "for delta_ in (delta_arr):\n",
    "    for k in (k_arr):\n",
    "        \n",
    "        print ('delta : ' + str(delta_)+ ' k : '+ str(k))\n",
    "        \n",
    "        context_size = (k*k-1)*nb_classes\n",
    "\n",
    "        X_data = np.zeros((len_tr_dataset*x_size*y_size,context_size))\n",
    "        Y_data = np.zeros((len_tr_dataset*x_size*y_size,3))\n",
    "\n",
    "        for img_idx in range(len_tr_dataset):\n",
    "\n",
    "            ## generate X_data\n",
    "            context_data = np.zeros((x_size*y_size,(k*k-1)))\n",
    "\n",
    "            img = binary_bsd_dataset[img_idx].copy()\n",
    "            noisy_img = add_noise(img, delta_)\n",
    "\n",
    "            padding_binary_bsd_data = np.pad(noisy_img,(k//2,k//2),'constant',constant_values=(0, 0))\n",
    "\n",
    "            patches = image.extract_patches_2d(padding_binary_bsd_data, (k,k))\n",
    "            flatten_patches = patches.reshape((patches.shape[0],patches.shape[1]*patches.shape[2]))\n",
    "\n",
    "            context_data[:,0:(k*k-1)//2] =  flatten_patches[:,0:(k*k-1)//2]\n",
    "            context_data[:,(k*k-1)//2:] =  flatten_patches[:,(k*k-1)//2+1:]\n",
    "            \n",
    "            flatten_onehot_context = get_onehot_context(context_data, nb_classes)\n",
    "\n",
    "            X_data[img_idx*(x_size*y_size):(img_idx+1)*(x_size*y_size),:] = flatten_onehot_context[:]\n",
    "\n",
    "            ## generate Y_data\n",
    "            label_data = np.zeros((x_size*y_size,3))\n",
    "\n",
    "            flatten_img = img.flatten()\n",
    "            flatten_noisy_img = noisy_img.flatten()\n",
    "\n",
    "            for idx in range(x_size*y_size):\n",
    "                true_pixel = flatten_img[idx]\n",
    "                noisy_pixel = flatten_noisy_img[idx]\n",
    "\n",
    "                if (true_pixel == 0) and (noisy_pixel == 0):\n",
    "                    label_data[idx,0] = 1\n",
    "                    label_data[idx,1] = 1\n",
    "                elif (true_pixel == 0) and (noisy_pixel == 1):\n",
    "                    label_data[idx,1] = 1\n",
    "                elif (true_pixel == 1) and (noisy_pixel == 0):\n",
    "                    label_data[idx,2] = 1\n",
    "                else:\n",
    "                    label_data[idx,0] = 1\n",
    "                    label_data[idx,2] = 1\n",
    "\n",
    "            Y_data[img_idx*(x_size*y_size):(img_idx+1)*(x_size*y_size),:] = label_data[:]\n",
    "            \n",
    "        f = h5py.File(\"NDUDE_sup_training_data_k\"+(str(k))+\"_delta\"+(str(int(delta_*100)))+\".hdf5\", \"w\")\n",
    "        f.create_dataset('X_data', data=X_data)\n",
    "        f.create_dataset('Y_data', data=Y_data)\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
